{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import os, pickle\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import regularizers\n",
    "from keras.wrappers.scikit_learn import KerasRegressor # this is for making a model like every other in scikit\n",
    "from keras.models import load_model, model_from_json\n",
    "# from sklearn.decomposition import TruncatedSVD as tSVD\n",
    "\n",
    "import  matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "random_seed = 2022\n",
    "np.random.seed(random_seed)\n",
    "nfolds=4\n",
    "njobs =3\n",
    "pathtosaved = 'D:/Sem8_FYP/TrainedModals/'\n",
    "#pathtosaved = 'D:/Sem8_FYP/Kanner/'\n",
    "print(pathtosaved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"Interactions_Trainset.tab\"):\n",
    "    \n",
    "    print(\"Loading train/valid sets...\")\n",
    "    Interactions_train = []    \n",
    "    with open(\"Interactions_Trainset.tab\",'r') as f:\n",
    "        for line in f:\n",
    "            tokens = line.split()\n",
    "            # 'Target-ID', 'Compound-ID', 'pIC50'  \n",
    "            Interactions_train.append( [tokens[0], tokens[1], float(tokens[2]) ])\n",
    "    \n",
    "    Interactions_valid = []        \n",
    "    with open(\"Interactions_Validset.tab\",'r') as f:\n",
    "        for line in f:\n",
    "            tokens = line.split()\n",
    "            # 'Target-ID', 'Compound-ID', 'pIC50'  \n",
    "            Interactions_valid.append( [tokens[0], tokens[1], float(tokens[2]) ])\n",
    "\n",
    "            \n",
    "Interactions = [x for x in Interactions_train]\n",
    "Interactions.extend(Interactions_valid)\n",
    "print(\"Basic stats about whole - train - validation sets:\")\n",
    "print( np.mean([x[2] for x in Interactions]), '\\t', np.mean([x[2] for x in Interactions_valid]), '\\t', np.mean([x[2] for x in Interactions_train]) )\n",
    "print( np.std([x[2] for x in Interactions]) , '\\t', np.std([x[2] for x in Interactions_valid]) , '\\t', np.std([x[2] for x in Interactions_train])  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.DataFrame( Interactions, columns =['Target-ID', 'Compound-ID','Std-value']) \n",
    "temp = DF.groupby(['Target-ID']).agg('count').sort_values(by='Compound-ID') # count the number of molecules\n",
    "Targets = list(temp.index)\n",
    "Compounds = np.unique(DF['Compound-ID'])\n",
    "\n",
    "nT=len(Targets); nC=len(Compounds)\n",
    "\n",
    "print(\"There are {0} targets and {1} compounds currently loaded with {2} interactions.\".format(nT,nC,len(Interactions)))\n",
    "print(\"A DTI matrix would be {0:.4}% dense!\".format(100.0*len(Interactions)/nT/nC ))\n",
    "\n",
    "\n",
    "Fingerprints={} \n",
    "with open('Compound_Fingerprints.tab', 'r') as f:\n",
    "    header = f.readline()\n",
    "    for line in f:\n",
    "        # each line is Comp-ID, SMILES, FP\n",
    "        tokens = line.split()\n",
    "        \n",
    "        if tokens[2] != 'NOFP':\n",
    "            fp = [int(c) for c in tokens[2] ]\n",
    "            Fingerprints[ tokens[0] ] = fp\n",
    "print(\"%d fingerprints were loaded!\" % len(Fingerprints))\n",
    "\n",
    "#del temp, DF, Interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Target_info = {} \n",
    "\n",
    "RF_all = dict()\n",
    "Scores_RF_train=[]\n",
    "count=0\n",
    "param_grid={'n_estimators':[10,25,50,100,150], 'max_depth':[3,4,5,7,10,15,20], 'max_features':['sqrt','auto']}\n",
    "for target in Targets:\n",
    "    Target_info[target] = {}\n",
    "    \n",
    "    X_train=[]; Y_train=[]\n",
    "    for point in Interactions_train:\n",
    "        if point[0]==target:\n",
    "            X_train.append( Fingerprints[point[1]] )\n",
    "            Y_train.append( float(point[2]) )\n",
    "    Target_info[target]['train_size']=len(Y_train) # add info\n",
    "    if len(Y_train)>40:\n",
    "        if os.path.isfile(pathtosaved+'RF_'+target+'_'+'pIC50new.sav'):\n",
    "            \n",
    "            with open( pathtosaved+'RF_'+target+'_'+'pIC50new.sav', 'rb') as f:\n",
    "                RFR = pickle.load( f )\n",
    "        else:\n",
    "            print(\"training...\")\n",
    "            \n",
    "            cvr = GridSearchCV(RandomForestRegressor(random_state=2019), param_grid, cv=nfolds, n_jobs=njobs, iid=True)\n",
    "            cvr.fit(X_train, Y_train)\n",
    "            \n",
    "            RFR = RandomForestRegressor( n_estimators= cvr.best_params_['n_estimators'],max_features=cvr.best_params_['max_features'], max_depth=cvr.best_params_['max_depth'], random_state=2019)\n",
    "            RFR.fit(X_train,Y_train)\n",
    "            # save model\n",
    "            pickle.dump(RFR, open(pathtosaved+'RF_'+target+'_'+'pIC50new.sav', 'wb'))\n",
    "        RF_all[target] = RFR\n",
    "        Scores_RF_train.append( RFR.score( X_train,  Y_train))\n",
    "        Target_info[target]['RF_train_r2'] = Scores_RF_train[-1] # add info\n",
    "#         print(Scores_RFR_train[-1])\n",
    "    else:\n",
    "        print(\"Not enough data for %s\" % target)\n",
    "    if count%25==0:\n",
    "        print(\"More than %d targets are processed\" % count)\n",
    "        print(\"Mean score so far: %f\" % np.mean(Scores_RF_train))\n",
    "    count+=1\n",
    "    \n",
    "print(\"Mean score for RF during training = %f\" % np.mean(Scores_RF_train) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "LR_all = dict()\n",
    "Scores_LR_train=[]\n",
    "param_grid={'alpha':[1, 0.5, 0.1, 0.01]}\n",
    "count=0\n",
    "for target in Targets:\n",
    "    # define the train set\n",
    "    X_train=[]; Y_train=[]\n",
    "    for point in Interactions_train:\n",
    "        if point[0]==target:\n",
    "            X_train.append( Fingerprints[point[1]] )\n",
    "            Y_train.append( float(point[2]) )\n",
    "    \n",
    "    if os.path.isfile(pathtosaved+'LR_'+target+'_'+'pIC50new.sav'):\n",
    "        # model is already trained - just load\n",
    "        with open( pathtosaved+'LR_'+target+'_'+'pIC50new.sav', 'rb') as f:\n",
    "            LR = pickle.load( f )\n",
    "    else:\n",
    "        print(\"cross validation\")\n",
    "        cvr = GridSearchCV(Lasso(random_state=2019, max_iter=3000), param_grid, cv=nfolds, n_jobs=njobs, iid=True)\n",
    "        cvr.fit(X_train, Y_train)\n",
    "        # select best parametrisation\n",
    "        LR = Lasso( alpha= cvr.best_params_['alpha'], max_iter=3000, random_state=2019)\n",
    "        LR.fit(X_train,Y_train)\n",
    "        pickle.dump(LR, open(pathtosaved+'LR_'+target+'_'+'pIC50new.sav', 'wb'))\n",
    "        \n",
    "    Scores_LR_train.append( LR.score( X_train,  Y_train))\n",
    "    Target_info[target]['LR_train_r2'] = Scores_LR_train[-1] # add info\n",
    "    LR_all[target] = LR\n",
    "    if count%25==0:\n",
    "        print(\"More than %d targets are processed\" % count)\n",
    "        print(\"Mean score so far: %f\" % np.mean(Scores_LR_train))\n",
    "    count+=1 \n",
    "\n",
    "print(\"Mean score for LR during training = %f\" % np.mean(Scores_LR_train) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_all = dict()\n",
    "Scores_NN_train=[]\n",
    "param_grid={'hidden_layer_sizes':[(50),(100,20),(100,50),(500,20,10)] }\n",
    "count=0\n",
    "for target in Targets:\n",
    "    # define the train set\n",
    "    X_train=[]; Y_train=[]\n",
    "    for point in Interactions_train:\n",
    "        if point[0]==target:\n",
    "            X_train.append( Fingerprints[point[1]] )\n",
    "            Y_train.append( float(point[2]) )\n",
    "    if os.path.isfile(pathtosaved+'NN_'+target+'_'+'pIC50new.sav'):\n",
    "        # model is already trained - just load\n",
    "        with open( pathtosaved+'NN_'+target+'_'+'pIC50new.sav', 'rb') as f:\n",
    "            MLPR = pickle.load( f )\n",
    "    else:\n",
    "        # we need to ensure there is enough data for CV\n",
    "        cvr = GridSearchCV(MLPRegressor(activation='tanh', solver='lbfgs', random_state=2019), param_grid, cv=nfolds, n_jobs=njobs, iid=True)\n",
    "        cvr.fit(X_train, Y_train)\n",
    "        # select best parametrisation and train to the complete train-set\n",
    "        MLPR = MLPRegressor( hidden_layer_sizes = cvr.best_params_['hidden_layer_sizes'], activation='tanh', solver='lbfgs', random_state=2019)\n",
    "        MLPR.fit(X_train,Y_train)\n",
    "        pickle.dump(MLPR, open(pathtosaved+'NN_'+target+'_'+'pIC50new.sav', 'wb'))\n",
    "    NN_all[target] = MLPR\n",
    "    Scores_NN_train.append( MLPR.score( X_train,  Y_train))\n",
    "    Target_info[target]['NN_train_r2'] = Scores_NN_train[-1] # add info\n",
    "    if count%25==0:\n",
    "        print(\"More than %d targets are processed\" % count)\n",
    "        print(\"Mean score so far: %f\" % np.mean(Scores_NN_train))\n",
    "    count+=1\n",
    "    \n",
    "print(\"Mean score for NN during training = %f\" % np.mean(Scores_NN_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for RF = 0.648058\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Pred_RF  = []\n",
    "True_vals = []\n",
    "Pred_pertarget = dict() \n",
    "\n",
    "Time_RF=0; Time_NN=0; Time_LR=0; Time_my=0\n",
    "with open(\"SingleTL_final_results.txt\",'w') as f:\n",
    "\n",
    "    f.write(\"Target\\tCompound\\tTrue\\tRFR\\n\")\n",
    "    for point in Interactions_valid:\n",
    "        # point = [ target, compound, pIC50 ]\n",
    "        True_vals.append( float(point[2]) )\n",
    "        x_test = np.array( Fingerprints[point[1]] ).reshape(1,-1) # prepare for prediction\n",
    "        \n",
    "        t0=time()\n",
    "        model = RF_all[point[0]]\n",
    "        Pred_RF.append( model.predict( x_test ) )\n",
    "        Time_RF+=time()-t0\n",
    "        #print(\"Random Forest Time\", Time_RF)\n",
    "        f.write(\"{0}\\t{1}\\t{2}\\t{3}\\n\".format(point[0], point[1], point[2], Pred_RF[-1][0]))\n",
    "\n",
    "        if point[0] in Pred_pertarget:\n",
    "            Pred_pertarget[point[0]].append( (True_vals[-1], Pred_RF[-1][0])  )\n",
    "            #print(Pred_pertarget[point[0]])\n",
    "        else:\n",
    "            # first time for this protein\n",
    "            Pred_pertarget[point[0]] = [ (True_vals[-1], Pred_RF[-1][0]) ]\n",
    "            #print(Pred_pertarget[point[0]])\n",
    "        \n",
    "print(\"Performance for RF = %f\" % r2_score( True_vals, Pred_RF ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: Duration per 1000 predictions = 17.15110715641834\n"
     ]
    }
   ],
   "source": [
    "print(\"RF: Duration per 1000 predictions = {0}\".format(1000*Time_RF/len(Interactions_valid) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for CHEMBL260, RF = 0.59\n",
      "R2 score for CHEMBL4722, RF = 0.68\n",
      "R2 score for CHEMBL2695, RF = 0.72\n",
      "R2 score for CHEMBL3038477, RF = 0.44\n",
      "R2 score for CHEMBL2996, RF = 0.51\n",
      "R2 score for CHEMBL2148, RF = 0.74\n",
      "R2 score for CHEMBL2147, RF = 0.66\n",
      "R2 score for CHEMBL5147, RF = 0.42\n",
      "R2 score for CHEMBL308, RF = 0.51\n",
      "R2 score for CHEMBL3234, RF = 0.54\n",
      "R2 score for CHEMBL4523, RF = 0.62\n",
      "R2 score for CHEMBL2358, RF = 0.31\n",
      "R2 score for CHEMBL1936, RF = 0.46\n",
      "R2 score for CHEMBL3629, RF = 0.47\n",
      "R2 score for CHEMBL279, RF = 0.51\n",
      "R2 score for CHEMBL1824, RF = 0.60\n",
      "R2 score for CHEMBL203, RF = 0.58\n",
      "R2 score for CHEMBL1862, RF = 0.64\n",
      "R2 score for CHEMBL3553, RF = 0.50\n",
      "R2 score for CHEMBL3529, RF = 0.55\n",
      "R2 score for CHEMBL299, RF = 0.83\n",
      "R2 score for CHEMBL4040, RF = 0.33\n",
      "R2 score for CHEMBL2828, RF = 0.79\n",
      "R2 score for CHEMBL2599, RF = 0.62\n",
      "R2 score for CHEMBL3973, RF = 0.65\n",
      "R2 score for CHEMBL1957, RF = 0.64\n",
      "R2 score for CHEMBL2095942, RF = 0.29\n",
      "R2 score for CHEMBL2185, RF = 0.63\n",
      "R2 score for CHEMBL2094126, RF = 0.30\n",
      "R2 score for CHEMBL2959, RF = 0.68\n",
      "R2 score for CHEMBL4630, RF = 0.30\n",
      "R2 score for CHEMBL1913, RF = 0.61\n",
      "R2 score for CHEMBL3920, RF = 0.56\n",
      "R2 score for CHEMBL1907601, RF = 0.70\n",
      "R2 score for CHEMBL1868, RF = 0.47\n",
      "R2 score for CHEMBL4376, RF = -0.24\n",
      "R2 score for CHEMBL1974, RF = 0.47\n",
      "R2 score for CHEMBL2842, RF = 0.50\n",
      "R2 score for CHEMBL3983, RF = 0.72\n",
      "R2 score for CHEMBL1981, RF = 0.68\n",
      "R2 score for CHEMBL2971, RF = 0.63\n",
      "R2 score for CHEMBL331, RF = 0.72\n",
      "R2 score for CHEMBL4439, RF = 0.70\n",
      "R2 score for CHEMBL3717, RF = 0.52\n",
      "R2 score for CHEMBL4224, RF = 0.47\n",
      "R2 score for CHEMBL4070, RF = 0.45\n",
      "R2 score for CHEMBL2637, RF = 0.54\n",
      "R2 score for CHEMBL2276, RF = 0.50\n",
      "R2 score for CHEMBL4282, RF = 0.56\n",
      "R2 score for CHEMBL2094138, RF = 0.38\n",
      "R2 score for CHEMBL301, RF = 0.58\n",
      "R2 score for CHEMBL3582, RF = 0.43\n",
      "R2 score for CHEMBL5408, RF = 0.34\n",
      "R2 score for CHEMBL1907600, RF = 0.55\n",
      "R2 score for CHEMBL1907605, RF = 0.36\n",
      "R2 score for CHEMBL5407, RF = 0.48\n",
      "R2 score for CHEMBL5543, RF = 0.44\n",
      "R2 score for CHEMBL4937, RF = 0.58\n",
      "R2 score for CHEMBL3476, RF = 0.66\n",
      "R2 score for CHEMBL2094127, RF = 0.32\n",
      "R2 score for CHEMBL5570, RF = 0.20\n",
      "R2 score for CHEMBL4895, RF = 0.33\n",
      "R2 score for CHEMBL2292, RF = 0.44\n",
      "R2 score for CHEMBL3650, RF = 0.67\n",
      "R2 score for CHEMBL2095217, RF = 0.43\n",
      "R2 score for CHEMBL3231, RF = 0.44\n",
      "R2 score for CHEMBL1906, RF = 0.27\n",
      "R2 score for CHEMBL1844, RF = 0.69\n",
      "R2 score for CHEMBL2363049, RF = 0.46\n",
      "R2 score for CHEMBL3616, RF = 0.09\n",
      "R2 score for CHEMBL4816, RF = 0.49\n",
      "R2 score for CHEMBL3038469, RF = 0.63\n",
      "R2 score for CHEMBL2068, RF = 0.51\n",
      "R2 score for CHEMBL2815, RF = 0.55\n",
      "R2 score for CHEMBL4247, RF = 0.50\n",
      "R2 score for CHEMBL2850, RF = 0.45\n",
      "R2 score for CHEMBL2094128, RF = 0.65\n",
      "R2 score for CHEMBL4179, RF = 0.49\n",
      "R2 score for CHEMBL4501, RF = 0.61\n",
      "R2 score for CHEMBL4142, RF = 0.52\n",
      "R2 score for CHEMBL2749, RF = 0.46\n",
      "R2 score for CHEMBL2431, RF = 0.66\n",
      "R2 score for CHEMBL3009, RF = 0.64\n",
      "R2 score for CHEMBL2095227, RF = 0.54\n",
      "R2 score for CHEMBL3142, RF = 0.49\n",
      "R2 score for CHEMBL2041, RF = 0.32\n",
      "R2 score for CHEMBL5331, RF = 0.51\n",
      "R2 score for CHEMBL1907602, RF = 0.42\n",
      "R2 score for CHEMBL2095188, RF = 0.42\n",
      "R2 score for CHEMBL2208, RF = 0.31\n",
      "R2 score for CHEMBL1955, RF = 0.55\n",
      "R2 score for CHEMBL3024, RF = 0.55\n",
      "R2 score for CHEMBL5508, RF = 0.38\n",
      "R2 score for CHEMBL2508, RF = 0.61\n",
      "R2 score for CHEMBL3905, RF = 0.29\n",
      "R2 score for CHEMBL3430907, RF = 0.67\n",
      "R2 score for CHEMBL258, RF = 0.59\n",
      "R2 score for CHEMBL4898, RF = 0.42\n",
      "R2 score for CHEMBL5491, RF = 0.57\n",
      "R2 score for CHEMBL4036, RF = 0.25\n",
      "R2 score for CHEMBL2111414, RF = 0.29\n",
      "R2 score for CHEMBL3797, RF = 0.99\n",
      "R2 score for CHEMBL3961, RF = 0.24\n",
      "R2 score for CHEMBL2094115, RF = 0.51\n",
      "R2 score for CHEMBL5314, RF = 0.31\n",
      "R2 score for CHEMBL1991, RF = 0.46\n",
      "R2 score for CHEMBL5122, RF = 0.37\n",
      "R2 score for CHEMBL2007, RF = 0.57\n",
      "R2 score for CHEMBL4203, RF = 0.02\n",
      "R2 score for CHEMBL3116, RF = 0.52\n"
     ]
    }
   ],
   "source": [
    "Scores_RF_valid_pertarget = []\n",
    "\n",
    "for target in Pred_pertarget:\n",
    "    true=[]\n",
    "    pred_RF=[]\n",
    "    # aggregate predictions\n",
    "    for point in Pred_pertarget[target]:\n",
    "        true.append( point[0] )\n",
    "        pred_RF.append( point[1] )\n",
    "        \n",
    "    Target_info[target]['test_size']=len(true) # add info\n",
    "    \n",
    "    # calculate performance for each method\n",
    "    r2 = r2_score(true, pred_RF)\n",
    "    Target_info[target]['RF_valid_r2'] = r2 # add info\n",
    "    Scores_RF_valid_pertarget.append( r2 )\n",
    "\n",
    "    print(\"R2 score for {0}, RF = {1:.2f}\".format(target, Scores_RF_valid_pertarget[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
