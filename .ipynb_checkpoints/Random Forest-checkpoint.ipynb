{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Sem8_FYP/TrainedModals/\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import os, pickle\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import regularizers\n",
    "from keras.wrappers.scikit_learn import KerasRegressor # this is for making a model like every other in scikit\n",
    "from keras.models import load_model, model_from_json\n",
    "# from sklearn.decomposition import TruncatedSVD as tSVD\n",
    "\n",
    "import  matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "random_seed = 2022\n",
    "np.random.seed(random_seed)\n",
    "nfolds=4\n",
    "njobs =3\n",
    "pathtosaved = 'D:/Sem8_FYP/TrainedModals/'\n",
    "#pathtosaved = 'D:/Sem8_FYP/Kanner/'\n",
    "print(pathtosaved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train/valid sets...\n",
      "Basic stats about whole - train - validation sets:\n",
      "-4.604582905766776 \t -4.59704615942543 \t -4.606467008822095\n",
      "2.5887050795505413 \t 2.573166842872859 \t 2.592571493135172\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(\"Interactions_Trainset.tab\"):\n",
    "    \n",
    "    print(\"Loading train/valid sets...\")\n",
    "    Interactions_train = []    \n",
    "    with open(\"Interactions_Trainset.tab\",'r') as f:\n",
    "        for line in f:\n",
    "            tokens = line.split()\n",
    "            # 'Target-ID', 'Compound-ID', 'pIC50'  \n",
    "            Interactions_train.append( [tokens[0], tokens[1], float(tokens[2]) ])\n",
    "    \n",
    "    Interactions_valid = []        \n",
    "    with open(\"Interactions_Validset.tab\",'r') as f:\n",
    "        for line in f:\n",
    "            tokens = line.split()\n",
    "            # 'Target-ID', 'Compound-ID', 'pIC50'  \n",
    "            Interactions_valid.append( [tokens[0], tokens[1], float(tokens[2]) ])\n",
    "\n",
    "            \n",
    "Interactions = [x for x in Interactions_train]\n",
    "Interactions.extend(Interactions_valid)\n",
    "print(\"Basic stats about whole - train - validation sets:\")\n",
    "print( np.mean([x[2] for x in Interactions]), '\\t', np.mean([x[2] for x in Interactions_valid]), '\\t', np.mean([x[2] for x in Interactions_train]) )\n",
    "print( np.std([x[2] for x in Interactions]) , '\\t', np.std([x[2] for x in Interactions_valid]) , '\\t', np.std([x[2] for x in Interactions_train])  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 110 targets and 23167 compounds currently loaded with 56392 interactions.\n",
      "A DTI matrix would be 2.213% dense!\n",
      "23167 fingerprints were loaded!\n"
     ]
    }
   ],
   "source": [
    "DF = pd.DataFrame( Interactions, columns =['Target-ID', 'Compound-ID','Std-value']) \n",
    "temp = DF.groupby(['Target-ID']).agg('count').sort_values(by='Compound-ID') # count the number of molecules\n",
    "Targets = list(temp.index)\n",
    "Compounds = np.unique(DF['Compound-ID'])\n",
    "\n",
    "nT=len(Targets); nC=len(Compounds)\n",
    "\n",
    "print(\"There are {0} targets and {1} compounds currently loaded with {2} interactions.\".format(nT,nC,len(Interactions)))\n",
    "print(\"A DTI matrix would be {0:.4}% dense!\".format(100.0*len(Interactions)/nT/nC ))\n",
    "\n",
    "\n",
    "Fingerprints={} \n",
    "with open('Compound_Fingerprints.tab', 'r') as f:\n",
    "    header = f.readline()\n",
    "    for line in f:\n",
    "        # each line is Comp-ID, SMILES, FP\n",
    "        tokens = line.split()\n",
    "        \n",
    "        if tokens[2] != 'NOFP':\n",
    "            fp = [int(c) for c in tokens[2] ]\n",
    "            Fingerprints[ tokens[0] ] = fp\n",
    "print(\"%d fingerprints were loaded!\" % len(Fingerprints))\n",
    "\n",
    "#del temp, DF, Interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More than 0 targets are processed\n",
      "Mean score so far: 0.914986\n",
      "More than 25 targets are processed\n",
      "Mean score so far: 0.905699\n",
      "More than 50 targets are processed\n",
      "Mean score so far: 0.904414\n",
      "More than 75 targets are processed\n",
      "Mean score so far: 0.906544\n",
      "More than 100 targets are processed\n",
      "Mean score so far: 0.900028\n",
      "Mean score for RF during training = 0.898134\n"
     ]
    }
   ],
   "source": [
    "Target_info = {} \n",
    "\n",
    "RF_all = dict()\n",
    "Scores_RF_train=[]\n",
    "count=0\n",
    "param_grid={'n_estimators':[10,25,50,100,150], 'max_depth':[3,4,5,7,10,15,20], 'max_features':['sqrt','auto']}\n",
    "for target in Targets:\n",
    "    Target_info[target] = {}\n",
    "    \n",
    "    X_train=[]; Y_train=[]\n",
    "    for point in Interactions_train:\n",
    "        if point[0]==target:\n",
    "            X_train.append( Fingerprints[point[1]] )\n",
    "            Y_train.append( float(point[2]) )\n",
    "    Target_info[target]['train_size']=len(Y_train) # add info\n",
    "    if len(Y_train)>40:\n",
    "        if os.path.isfile(pathtosaved+'RF_'+target+'_'+'pIC50new.sav'):\n",
    "            \n",
    "            with open( pathtosaved+'RF_'+target+'_'+'pIC50new.sav', 'rb') as f:\n",
    "                RFR = pickle.load( f )\n",
    "        else:\n",
    "            print(\"training...\")\n",
    "            \n",
    "            cvr = GridSearchCV(RandomForestRegressor(random_state=2019), param_grid, cv=nfolds, n_jobs=njobs, iid=True)\n",
    "            cvr.fit(X_train, Y_train)\n",
    "            \n",
    "            RFR = RandomForestRegressor( n_estimators= cvr.best_params_['n_estimators'],max_features=cvr.best_params_['max_features'], max_depth=cvr.best_params_['max_depth'], random_state=2019)\n",
    "            RFR.fit(X_train,Y_train)\n",
    "            # save model\n",
    "            pickle.dump(RFR, open(pathtosaved+'RF_'+target+'_'+'pIC50new.sav', 'wb'))\n",
    "        RF_all[target] = RFR\n",
    "        Scores_RF_train.append( RFR.score( X_train,  Y_train))\n",
    "        Target_info[target]['RF_train_r2'] = Scores_RF_train[-1] # add info\n",
    "#         print(Scores_RFR_train[-1])\n",
    "    else:\n",
    "        print(\"Not enough data for %s\" % target)\n",
    "    if count%25==0:\n",
    "        print(\"More than %d targets are processed\" % count)\n",
    "        print(\"Mean score so far: %f\" % np.mean(Scores_RF_train))\n",
    "    count+=1\n",
    "    \n",
    "print(\"Mean score for RF during training = %f\" % np.mean(Scores_RF_train) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More than 0 targets are processed\n",
      "Mean score so far: 0.635198\n",
      "More than 25 targets are processed\n",
      "Mean score so far: 0.782202\n",
      "More than 50 targets are processed\n",
      "Mean score so far: 0.785533\n",
      "More than 75 targets are processed\n",
      "Mean score so far: 0.778149\n",
      "More than 100 targets are processed\n",
      "Mean score so far: 0.760982\n",
      "Mean score for LR during training = 0.752432\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "LR_all = dict()\n",
    "Scores_LR_train=[]\n",
    "param_grid={'alpha':[1, 0.5, 0.1, 0.01]}\n",
    "count=0\n",
    "for target in Targets:\n",
    "    # define the train set\n",
    "    X_train=[]; Y_train=[]\n",
    "    for point in Interactions_train:\n",
    "        if point[0]==target:\n",
    "            X_train.append( Fingerprints[point[1]] )\n",
    "            Y_train.append( float(point[2]) )\n",
    "    \n",
    "    if os.path.isfile(pathtosaved+'LR_'+target+'_'+'pIC50new.sav'):\n",
    "        # model is already trained - just load\n",
    "        with open( pathtosaved+'LR_'+target+'_'+'pIC50new.sav', 'rb') as f:\n",
    "            LR = pickle.load( f )\n",
    "    else:\n",
    "        print(\"cross validation\")\n",
    "        cvr = GridSearchCV(Lasso(random_state=2019, max_iter=3000), param_grid, cv=nfolds, n_jobs=njobs, iid=True)\n",
    "        cvr.fit(X_train, Y_train)\n",
    "        # select best parametrisation\n",
    "        LR = Lasso( alpha= cvr.best_params_['alpha'], max_iter=3000, random_state=2019)\n",
    "        LR.fit(X_train,Y_train)\n",
    "        pickle.dump(LR, open(pathtosaved+'LR_'+target+'_'+'pIC50new.sav', 'wb'))\n",
    "        \n",
    "    Scores_LR_train.append( LR.score( X_train,  Y_train))\n",
    "    Target_info[target]['LR_train_r2'] = Scores_LR_train[-1] # add info\n",
    "    LR_all[target] = LR\n",
    "    if count%25==0:\n",
    "        print(\"More than %d targets are processed\" % count)\n",
    "        print(\"Mean score so far: %f\" % np.mean(Scores_LR_train))\n",
    "    count+=1 \n",
    "\n",
    "print(\"Mean score for LR during training = %f\" % np.mean(Scores_LR_train) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More than 0 targets are processed\n",
      "Mean score so far: 0.999993\n",
      "More than 25 targets are processed\n",
      "Mean score so far: 0.995383\n",
      "More than 50 targets are processed\n",
      "Mean score so far: 0.995712\n",
      "More than 75 targets are processed\n",
      "Mean score so far: 0.995595\n",
      "More than 100 targets are processed\n",
      "Mean score so far: 0.993710\n",
      "Mean score for NN during training = 0.993015\n"
     ]
    }
   ],
   "source": [
    "NN_all = dict()\n",
    "Scores_NN_train=[]\n",
    "param_grid={'hidden_layer_sizes':[(50),(100,20),(100,50),(500,20,10)] }\n",
    "count=0\n",
    "for target in Targets:\n",
    "    # define the train set\n",
    "    X_train=[]; Y_train=[]\n",
    "    for point in Interactions_train:\n",
    "        if point[0]==target:\n",
    "            X_train.append( Fingerprints[point[1]] )\n",
    "            Y_train.append( float(point[2]) )\n",
    "    if os.path.isfile(pathtosaved+'NN_'+target+'_'+'pIC50new.sav'):\n",
    "        # model is already trained - just load\n",
    "        with open( pathtosaved+'NN_'+target+'_'+'pIC50new.sav', 'rb') as f:\n",
    "            MLPR = pickle.load( f )\n",
    "    else:\n",
    "        # we need to ensure there is enough data for CV\n",
    "        cvr = GridSearchCV(MLPRegressor(activation='tanh', solver='lbfgs', random_state=2019), param_grid, cv=nfolds, n_jobs=njobs, iid=True)\n",
    "        cvr.fit(X_train, Y_train)\n",
    "        # select best parametrisation and train to the complete train-set\n",
    "        MLPR = MLPRegressor( hidden_layer_sizes = cvr.best_params_['hidden_layer_sizes'], activation='tanh', solver='lbfgs', random_state=2019)\n",
    "        MLPR.fit(X_train,Y_train)\n",
    "        pickle.dump(MLPR, open(pathtosaved+'NN_'+target+'_'+'pIC50new.sav', 'wb'))\n",
    "    NN_all[target] = MLPR\n",
    "    Scores_NN_train.append( MLPR.score( X_train,  Y_train))\n",
    "    Target_info[target]['NN_train_r2'] = Scores_NN_train[-1] # add info\n",
    "    if count%25==0:\n",
    "        print(\"More than %d targets are processed\" % count)\n",
    "        print(\"Mean score so far: %f\" % np.mean(Scores_NN_train))\n",
    "    count+=1\n",
    "    \n",
    "print(\"Mean score for NN during training = %f\" % np.mean(Scores_NN_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for RF = 0.648058\n",
      "Performance for NN = 0.576625\n",
      "Performance for LR = 0.591053\n"
     ]
    }
   ],
   "source": [
    "Pred_NN = []; Pred_RF  = []; Pred_LR = []; \n",
    "True_vals = []\n",
    "Pred_pertarget = dict()\n",
    "\n",
    "Time_RF=0; Time_NN=0; Time_LR=0; \n",
    "with open(\"SingleTL_final_results.txt\",'w') as f:\n",
    "#     this file contains all the important stuff for the comparison\n",
    "    f.write(\"Target\\tCompound\\tTrue\\tRFR\\tMLPR\\tLR\\n\")\n",
    "    for point in Interactions_valid:\n",
    "        # point = [ target, compound, pIC50 ]\n",
    "        True_vals.append( float(point[2]) )\n",
    "        x_test = np.array( Fingerprints[point[1]] ).reshape(1,-1) # prepare for prediction\n",
    "        \n",
    "        t0=time()\n",
    "        model = RF_all[point[0]]\n",
    "        Pred_RF.append( model.predict( x_test ) )\n",
    "        Time_RF+=time()-t0\n",
    "        \n",
    "        t0=time()\n",
    "        model = NN_all[point[0]]\n",
    "        Pred_NN.append( model.predict( x_test ) )\n",
    "        Time_NN+=time()-t0\n",
    "        \n",
    "        t0=time()\n",
    "        model = LR_all[point[0]]\n",
    "        Pred_LR.append( model.predict( x_test ) )\n",
    "        Time_LR+=time()-t0\n",
    "        \n",
    "        \n",
    "        f.write(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}\\n\".format(point[0], point[1], point[2], Pred_RF[-1][0], Pred_NN[-1][0], Pred_LR[-1][0]))\n",
    "\n",
    "        if point[0] in Pred_pertarget:\n",
    "            Pred_pertarget[point[0]].append( (True_vals[-1], Pred_RF[-1][0], Pred_NN[-1][0], Pred_LR[-1][0])  )\n",
    "        else:\n",
    "            # first time for this protein\n",
    "            Pred_pertarget[point[0]] = [ (True_vals[-1], Pred_RF[-1][0], Pred_NN[-1][0], Pred_LR[-1][0]) ]\n",
    "        \n",
    "print(\"Performance for RF = %f\" % r2_score( True_vals, Pred_RF ))\n",
    "print(\"Performance for NN = %f\" % r2_score( True_vals, Pred_NN ))\n",
    "print(\"Performance for LR = %f\" % r2_score( True_vals, Pred_LR ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: Duration per 1000 predictions = 7.172511875005791\n",
      "LR: Duration per 1000 predictions = 0.0808683983250953\n",
      "NN: Duration per 1000 predictions = 0.5851604135604292\n"
     ]
    }
   ],
   "source": [
    "print(\"RF: Duration per 1000 predictions = {0}\".format(1000*Time_RF/len(Interactions_valid) ))\n",
    "print(\"LR: Duration per 1000 predictions = {0}\".format(1000*Time_LR/len(Interactions_valid) ))\n",
    "print(\"NN: Duration per 1000 predictions = {0}\".format(1000*Time_NN/len(Interactions_valid) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for CHEMBL260, RF | NN | LR  = 0.59 | 0.27 | 0.50 \n",
      "R2 score for CHEMBL4722, RF | NN | LR  = 0.68 | 0.53 | 0.59 \n",
      "R2 score for CHEMBL2695, RF | NN | LR  = 0.72 | 0.53 | 0.68 \n",
      "R2 score for CHEMBL3038477, RF | NN | LR  = 0.44 | 0.25 | 0.42 \n",
      "R2 score for CHEMBL2996, RF | NN | LR  = 0.51 | 0.46 | 0.46 \n",
      "R2 score for CHEMBL2148, RF | NN | LR  = 0.74 | 0.72 | 0.71 \n",
      "R2 score for CHEMBL2147, RF | NN | LR  = 0.66 | 0.63 | 0.66 \n",
      "R2 score for CHEMBL5147, RF | NN | LR  = 0.42 | 0.23 | 0.35 \n",
      "R2 score for CHEMBL308, RF | NN | LR  = 0.51 | 0.45 | 0.53 \n",
      "R2 score for CHEMBL3234, RF | NN | LR  = 0.54 | 0.45 | 0.32 \n",
      "R2 score for CHEMBL4523, RF | NN | LR  = 0.62 | 0.59 | 0.59 \n",
      "R2 score for CHEMBL2358, RF | NN | LR  = 0.31 | -0.16 | 0.26 \n",
      "R2 score for CHEMBL1936, RF | NN | LR  = 0.46 | 0.37 | 0.33 \n",
      "R2 score for CHEMBL3629, RF | NN | LR  = 0.47 | 0.54 | 0.54 \n",
      "R2 score for CHEMBL279, RF | NN | LR  = 0.51 | 0.43 | 0.38 \n",
      "R2 score for CHEMBL1824, RF | NN | LR  = 0.60 | 0.56 | 0.47 \n",
      "R2 score for CHEMBL203, RF | NN | LR  = 0.58 | 0.46 | 0.42 \n",
      "R2 score for CHEMBL1862, RF | NN | LR  = 0.64 | 0.59 | 0.65 \n",
      "R2 score for CHEMBL3553, RF | NN | LR  = 0.50 | 0.47 | 0.49 \n",
      "R2 score for CHEMBL3529, RF | NN | LR  = 0.55 | 0.53 | 0.56 \n",
      "R2 score for CHEMBL299, RF | NN | LR  = 0.83 | 0.77 | 0.80 \n",
      "R2 score for CHEMBL4040, RF | NN | LR  = 0.33 | 0.32 | 0.39 \n",
      "R2 score for CHEMBL2828, RF | NN | LR  = 0.79 | 0.74 | 0.78 \n",
      "R2 score for CHEMBL2599, RF | NN | LR  = 0.62 | 0.47 | 0.44 \n",
      "R2 score for CHEMBL3973, RF | NN | LR  = 0.65 | 0.44 | 0.55 \n",
      "R2 score for CHEMBL1957, RF | NN | LR  = 0.64 | 0.57 | 0.58 \n",
      "R2 score for CHEMBL2095942, RF | NN | LR  = 0.29 | 0.30 | 0.33 \n",
      "R2 score for CHEMBL2185, RF | NN | LR  = 0.63 | 0.49 | 0.55 \n",
      "R2 score for CHEMBL2094126, RF | NN | LR  = 0.30 | 0.28 | 0.26 \n",
      "R2 score for CHEMBL2959, RF | NN | LR  = 0.68 | 0.75 | 0.76 \n",
      "R2 score for CHEMBL4630, RF | NN | LR  = 0.30 | 0.14 | -0.01 \n",
      "R2 score for CHEMBL1913, RF | NN | LR  = 0.61 | 0.58 | 0.56 \n",
      "R2 score for CHEMBL3920, RF | NN | LR  = 0.56 | 0.31 | 0.54 \n",
      "R2 score for CHEMBL1907601, RF | NN | LR  = 0.70 | 0.64 | 0.66 \n",
      "R2 score for CHEMBL1868, RF | NN | LR  = 0.47 | 0.43 | 0.43 \n",
      "R2 score for CHEMBL4376, RF | NN | LR  = -0.24 | -0.28 | 0.04 \n",
      "R2 score for CHEMBL1974, RF | NN | LR  = 0.47 | 0.23 | 0.46 \n",
      "R2 score for CHEMBL2842, RF | NN | LR  = 0.50 | 0.48 | 0.41 \n",
      "R2 score for CHEMBL3983, RF | NN | LR  = 0.72 | 0.44 | 0.50 \n",
      "R2 score for CHEMBL1981, RF | NN | LR  = 0.68 | 0.58 | 0.58 \n",
      "R2 score for CHEMBL2971, RF | NN | LR  = 0.63 | 0.64 | 0.59 \n",
      "R2 score for CHEMBL331, RF | NN | LR  = 0.72 | 0.62 | 0.65 \n",
      "R2 score for CHEMBL4439, RF | NN | LR  = 0.70 | 0.47 | 0.67 \n",
      "R2 score for CHEMBL3717, RF | NN | LR  = 0.52 | 0.54 | 0.54 \n",
      "R2 score for CHEMBL4224, RF | NN | LR  = 0.47 | 0.31 | 0.34 \n",
      "R2 score for CHEMBL4070, RF | NN | LR  = 0.45 | 0.27 | 0.29 \n",
      "R2 score for CHEMBL2637, RF | NN | LR  = 0.54 | 0.48 | 0.49 \n",
      "R2 score for CHEMBL2276, RF | NN | LR  = 0.50 | 0.42 | 0.51 \n",
      "R2 score for CHEMBL4282, RF | NN | LR  = 0.56 | 0.51 | 0.45 \n",
      "R2 score for CHEMBL2094138, RF | NN | LR  = 0.38 | 0.40 | 0.31 \n",
      "R2 score for CHEMBL301, RF | NN | LR  = 0.58 | 0.54 | 0.54 \n",
      "R2 score for CHEMBL3582, RF | NN | LR  = 0.43 | 0.39 | 0.35 \n",
      "R2 score for CHEMBL5408, RF | NN | LR  = 0.34 | 0.33 | 0.24 \n",
      "R2 score for CHEMBL1907600, RF | NN | LR  = 0.55 | 0.46 | 0.52 \n",
      "R2 score for CHEMBL1907605, RF | NN | LR  = 0.36 | 0.38 | 0.35 \n",
      "R2 score for CHEMBL5407, RF | NN | LR  = 0.48 | 0.33 | 0.44 \n",
      "R2 score for CHEMBL5543, RF | NN | LR  = 0.44 | 0.34 | 0.46 \n",
      "R2 score for CHEMBL4937, RF | NN | LR  = 0.58 | 0.65 | 0.59 \n",
      "R2 score for CHEMBL3476, RF | NN | LR  = 0.66 | 0.44 | 0.59 \n",
      "R2 score for CHEMBL2094127, RF | NN | LR  = 0.32 | -0.02 | 0.21 \n",
      "R2 score for CHEMBL5570, RF | NN | LR  = 0.20 | -0.07 | -0.04 \n",
      "R2 score for CHEMBL4895, RF | NN | LR  = 0.33 | 0.39 | 0.32 \n",
      "R2 score for CHEMBL2292, RF | NN | LR  = 0.44 | 0.33 | 0.31 \n",
      "R2 score for CHEMBL3650, RF | NN | LR  = 0.67 | 0.54 | 0.60 \n",
      "R2 score for CHEMBL2095217, RF | NN | LR  = 0.43 | 0.45 | 0.34 \n",
      "R2 score for CHEMBL3231, RF | NN | LR  = 0.44 | 0.50 | 0.36 \n",
      "R2 score for CHEMBL1906, RF | NN | LR  = 0.27 | -0.01 | 0.24 \n",
      "R2 score for CHEMBL1844, RF | NN | LR  = 0.69 | 0.55 | 0.63 \n",
      "R2 score for CHEMBL2363049, RF | NN | LR  = 0.46 | 0.29 | 0.44 \n",
      "R2 score for CHEMBL3616, RF | NN | LR  = 0.09 | -0.04 | -0.08 \n",
      "R2 score for CHEMBL4816, RF | NN | LR  = 0.49 | 0.51 | 0.50 \n",
      "R2 score for CHEMBL3038469, RF | NN | LR  = 0.63 | 0.47 | 0.58 \n",
      "R2 score for CHEMBL2068, RF | NN | LR  = 0.51 | 0.36 | 0.30 \n",
      "R2 score for CHEMBL2815, RF | NN | LR  = 0.55 | 0.54 | 0.53 \n",
      "R2 score for CHEMBL4247, RF | NN | LR  = 0.50 | 0.39 | 0.41 \n",
      "R2 score for CHEMBL2850, RF | NN | LR  = 0.45 | 0.15 | 0.25 \n",
      "R2 score for CHEMBL2094128, RF | NN | LR  = 0.65 | 0.56 | 0.62 \n",
      "R2 score for CHEMBL4179, RF | NN | LR  = 0.49 | 0.34 | 0.44 \n",
      "R2 score for CHEMBL4501, RF | NN | LR  = 0.61 | 0.57 | 0.58 \n",
      "R2 score for CHEMBL4142, RF | NN | LR  = 0.52 | 0.59 | 0.52 \n",
      "R2 score for CHEMBL2749, RF | NN | LR  = 0.46 | 0.45 | 0.45 \n",
      "R2 score for CHEMBL2431, RF | NN | LR  = 0.66 | 0.58 | 0.62 \n",
      "R2 score for CHEMBL3009, RF | NN | LR  = 0.64 | 0.31 | 0.66 \n",
      "R2 score for CHEMBL2095227, RF | NN | LR  = 0.54 | 0.14 | 0.27 \n",
      "R2 score for CHEMBL3142, RF | NN | LR  = 0.49 | 0.45 | 0.30 \n",
      "R2 score for CHEMBL2041, RF | NN | LR  = 0.32 | 0.20 | 0.33 \n",
      "R2 score for CHEMBL5331, RF | NN | LR  = 0.51 | 0.51 | 0.50 \n",
      "R2 score for CHEMBL1907602, RF | NN | LR  = 0.42 | 0.51 | 0.22 \n",
      "R2 score for CHEMBL2095188, RF | NN | LR  = 0.42 | 0.13 | 0.19 \n",
      "R2 score for CHEMBL2208, RF | NN | LR  = 0.31 | 0.41 | 0.40 \n",
      "R2 score for CHEMBL1955, RF | NN | LR  = 0.55 | 0.29 | 0.48 \n",
      "R2 score for CHEMBL3024, RF | NN | LR  = 0.55 | 0.61 | 0.39 \n",
      "R2 score for CHEMBL5508, RF | NN | LR  = 0.38 | 0.21 | 0.09 \n",
      "R2 score for CHEMBL2508, RF | NN | LR  = 0.61 | 0.49 | 0.68 \n",
      "R2 score for CHEMBL3905, RF | NN | LR  = 0.29 | -0.17 | -0.36 \n",
      "R2 score for CHEMBL3430907, RF | NN | LR  = 0.67 | 0.71 | 0.63 \n",
      "R2 score for CHEMBL258, RF | NN | LR  = 0.59 | 0.46 | 0.45 \n",
      "R2 score for CHEMBL4898, RF | NN | LR  = 0.42 | 0.28 | 0.25 \n",
      "R2 score for CHEMBL5491, RF | NN | LR  = 0.57 | 0.44 | 0.65 \n",
      "R2 score for CHEMBL4036, RF | NN | LR  = 0.25 | 0.14 | 0.17 \n",
      "R2 score for CHEMBL2111414, RF | NN | LR  = 0.29 | 0.47 | 0.06 \n",
      "R2 score for CHEMBL3797, RF | NN | LR  = 0.99 | 0.99 | 0.97 \n",
      "R2 score for CHEMBL3961, RF | NN | LR  = 0.24 | 0.30 | -0.04 \n",
      "R2 score for CHEMBL2094115, RF | NN | LR  = 0.51 | 0.42 | 0.23 \n",
      "R2 score for CHEMBL5314, RF | NN | LR  = 0.31 | 0.08 | 0.10 \n",
      "R2 score for CHEMBL1991, RF | NN | LR  = 0.46 | 0.20 | 0.35 \n",
      "R2 score for CHEMBL5122, RF | NN | LR  = 0.37 | -0.49 | -0.09 \n",
      "R2 score for CHEMBL2007, RF | NN | LR  = 0.57 | 0.41 | 0.34 \n",
      "R2 score for CHEMBL4203, RF | NN | LR  = 0.02 | -0.58 | -0.04 \n",
      "R2 score for CHEMBL3116, RF | NN | LR  = 0.52 | 0.35 | 0.34 \n"
     ]
    }
   ],
   "source": [
    "Scores_RF_valid_pertarget = []\n",
    "Scores_NN_valid_pertarget = []\n",
    "Scores_LR_valid_pertarget = []\n",
    "\n",
    "\n",
    "for target in Pred_pertarget:\n",
    "    true=[]\n",
    "    pred_RF=[]; pred_NN=[]; pred_LR=[]; \n",
    "    # aggregate predictions\n",
    "    for point in Pred_pertarget[target]:\n",
    "        true.append( point[0] )\n",
    "        pred_RF.append( point[1] )\n",
    "        pred_NN.append( point[2] )\n",
    "        pred_LR.append( point[3] )\n",
    "        \n",
    "    Target_info[target]['test_size']=len(true) # add info\n",
    "    \n",
    "    # calculate performance for each method\n",
    "    r2 = r2_score(true, pred_RF)\n",
    "    Target_info[target]['RF_valid_r2'] = r2 # add info\n",
    "    Scores_RF_valid_pertarget.append( r2 )\n",
    "    \n",
    "    r2 = r2_score(true, pred_NN)\n",
    "    Target_info[target]['NN_valid_r2'] = r2 # add info\n",
    "    Scores_NN_valid_pertarget.append( r2 )\n",
    "\n",
    "    r2 = r2_score(true, pred_LR)\n",
    "    Target_info[target]['LR_valid_r2'] = r2 # add info\n",
    "    Scores_LR_valid_pertarget.append( r2 )\n",
    "    \n",
    "   \n",
    "\n",
    "    print(\"R2 score for {0}, RF | NN | LR  = {1:.2f} | {2:.2f} | {3:.2f} \".format(target, Scores_RF_valid_pertarget[-1], Scores_NN_valid_pertarget[-1], Scores_LR_valid_pertarget[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
